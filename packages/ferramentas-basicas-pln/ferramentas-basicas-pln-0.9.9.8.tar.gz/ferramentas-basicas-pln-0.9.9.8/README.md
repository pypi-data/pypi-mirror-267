
# Ferramentas b√°sicas para Processamento de Linguagem Natural

Este pacote √© um kit de ferramentas (variadas fun√ß√µes) para execu√ß√£o de processos b√°sicos relacionados as etapas iniciais de processamento de linguagem natural.

<details>
  <summary><b>Vers√£o em ingl√™s  <i>(clique para expandir)</i></b></summary>
  <br><ul>
  <li><i><a href="https://pypi.org/project/pre-processing-text-basic-tools/">Pypi package english version</a></i></li>
  <li><i><a href="https://github.com/IgorCaetano/pre_processing_text_basic_tools">GitHub repository english version</a></i></li></ul>
</details>


## ‚úÖ Funcionalidades

- Limpeza e padroniza√ß√£o de texto;
- An√°lise quantitativa de palavras no texto;
- Pr√©-processamento de texto (tokeniza√ß√£o) para posterior inser√ß√£o em modelos de vetoriza√ß√£o de palavras (Word Embeddings);
- F√°cil integra√ß√£o com outros programas Python por meio da importa√ß√£o do(s) m√≥dulo(s) ou fun√ß√µes desejadas.


## üì¶ Instala√ß√£o

A instala√ß√£o deste pacote se d√° por meio do comando "*pip install*"

```bash
pip install ferramentas-basicas-pln
```

<i>Se voc√™ estiver no GitHub</i> mais informa√ß√µes sobre o pacote no Pypi: <b><a href="https://pypi.org/project/ferramentas-basicas-pln/">ferramentas-basicas-pln pacote pypi</a></b>.


## üìú Uso/Exemplos

### ‚öôÔ∏è Fun√ß√µes b√°sicas ‚öôÔ∏è


<details>
  <summary>Removendo caracteres especiais do texto  <i>(clique para expandir)</i></summary>
  <br>
  
  ```python
  from ferramentas_basicas_pln import removerCaracteresEspeciais
  
  texto = "Este √© um $ exemplo, de texto? com caracteres# especiai.s. Quero limp√°-lo!!!"
  
  texto_limpo = removerCaracteresEspeciais(texto)
  
  print(texto_limpo)
  ```

  Output:
  
  ```python
  "Este √© um exemplo de texto com caracteres especiais Quero limp√°-lo"
  ```

  <details>
    <summary>! Observa√ß√£o importante sobre palavras com h√≠fen  <i>(clique para expandir)</i></summary>
    <br>
    √â importante destacar que as fun√ß√µes foram pensadas para aplica√ß√µes diretas para a l√≠ngua portuguesa. Com isso, palavras com h√≠fen, como sexta-feira, n√£o tem seu caracter especial "-" removido por padr√£o, mas pode-se optar pela remo√ß√£o dos h√≠fens de tais palavras       usando o par√¢metro <i>remover_hifen_de_palavras</i>, passando para <i>True</i>. Ainda, se quiser que os h√≠fens n√£o sejam substitu√≠dos por um espa√ßo " ", pode-se passar o par√¢metro <i>tratamento_personalizado</i> para <i>False</i>, o qual substitui caracteres "/",       "\" e "-" para " ".   
    <br><br>
    
  ```python
  from ferramentas_basicas_pln import removerCaracteresEspeciais

  texto = '''Hoje √© sexta-feira e dia 09/03/2024! Ou ainda 09-03-2024.'''


  texto_limpo = removerCaracteresEspeciais(texto,remover_hifen_de_palavras=True)

  print(texto_limpo)
  ```

  Output:

  ```python
  "Hoje √© sexta feira e dia 09 03 2024 Ou ainda 09 03 2024"
  ```
  </details>
  
  # 
  
</details>


<details>
  <summary>Formata√ß√£o e padroniza√ß√£o total do texto  <i>(clique para expandir)</i></summary>
  <br>
  
  ```python
  from ferramentas_basicas_pln import formatarTexto
  
  texto = "Este √© um $ exemplo, de texto? que/ que.ro# formatar e&*. padronizar!?"
  
  texto_formatado = formatarTexto(texto=texto,
                                  padronizar_texto_para_minuscula=True,
                                  remover_caracteres_especiais=True,
                                  remover_caracteres_mais_que_especiais=True,
                                  remover_espacos_em_branco_em_excesso=True,
                                  padronizar_com_unidecode=True)
  
  print(texto_formatado)
  ```
  
  Output:

  ```python
  "este e um exemplo de texto que quero formatar e padronizar"
  ```
</details>

<details>
  <summary>Padroniza√ß√£o de elementos espec√≠ficos - aplica√ß√£o de m√°scara  <i>(clique para expandir)</i></summary>
  <br>
  
  ```python
  from formatarTexto import formatarTexto
  
  texto = '''Se eu tiver um texto com e-mail tipo esteehumemail@gmail.com ou 
  noreply@hotmail.com ou at√© mesmo emaildeteste@yahoo.com.br.
  Al√©m disso terei tamb√©m v√°rios telefones do tipo +55 48 911223344 ou 
  4890011-2233 e por que n√£o um fixo do tipo 48 0011-2233?
  Pode-se ter tamb√©m datas como 12/12/2024 ou 2023-06-12 em variados tipos 
  tipo 1/2/24
  E se o texto tiver muito dinheiro envolvido? Falamos de R$ 200.000,00 ou 
  R$200,00 ou at√© com 
  a formata√ß√£o errada tipo R$   2500!
  Al√©m disso podemos simplesmente padronizar n√∫meros como 123123 ou 24 ou 
  129381233 ou at√© mesmo 1.200.234!'''
  
  texto_formatado = formatarTexto(texto=texto,                                        
                                  padronizar_com_unidecode=True,
                                  padronizar_datas=True,
                                  padrao_data='_data_',
                                  padronizar_dinheiros=True,
                                  padrao_dinheiro='$',
                                  padronizar_emails=True,
                                  padrao_email='_email_',
                                  padronizar_telefone_celular=True,
                                  padrao_tel='_tel_',
                                  padronizar_numeros=True,
                                  padrao_numero='0',
                                  padronizar_texto_para_minuscula=True)
  
  print(texto_formatado)
  ```

  Output:
  
  ```python
  """se eu tiver um texto com e-mail tipo _email_ ou _email_ ou ate mesmo _email_
  alem disso terei tambem varios telefones do tipo _tel_ ou _tel_ e por que nao um fixo do tipo _tel_
  pode-se ter tambem datas como _data_ ou _data_ em variados tipos tipo _data_
  e se o texto tiver muito dinheiro envolvido falamos de $ ou $ ou ate com 
  a formatacao errada tipo $
  alem disso podemos simplesmente padronizar numeros como 0 ou 0 ou 0 ou ate mesmo 0"""
  ```
</details>

<details>
  <summary>Contagem de frequ√™ncia de palavras no texto  <i>(clique para expandir)</i></summary>
  <br>
  
  Este kit de fun√ß√µes permite realizar a contagem de palavras em um texto. Por padr√£o, ele elimina da contagem as palavras contidas na lista de palavras de escape para calcular a frequ√™ncia: <i>lista_com_palavras_de_escape_padrao_frequencia</i>. Caso queira desativar esta funcionalidade, basta passar como par√¢metro "<i>remover_palavras_de_escape</i>=False". Abaixo temos um exemplo de um uso simples da fun√ß√£o de contar a frequ√™ncia de uma palavra numa determinada frase:

  ```python
  from ferramentas_basicas_pln import contarFrequenciaDePalavras

  texto = '''Aqui vai mais um exemplo de texto de exemplo para uma 
  demonstra√ß√£o de contagem de palavras num texto de exemplo com 
  v√°rias palavras.'''

  frequencias = contarFrequenciaDePalavras(texto=texto)

  for freq in frequencias:
      print(freq)
  ```
  
  Output:

  ```python
  ('exemplo', 3)
  ('texto', 2)
  ('palavras', 2)
  ('aqui', 1)
  ('vai', 1)
  ('demonstra√ß√£o', 1)
  ('contagem', 1)
  ('v√°rias', 1)
  ```

  Podemos tamb√©m selecionar palavras espec√≠ficas para realiza√ß√£o da contagem, passando a lista de palavras no par√¢metro <i>palavras_especificas</i>:

  ```python
  from ferramentas_basicas_pln import contarFrequenciaDePalavras

  texto = '''Aqui vai mais um exemplo de texto de exemplo para uma 
  demonstra√ß√£o de contagem de palavras num texto de exemplo com 
  v√°rias palavras.'''

  frequencias = contarFrequenciaDePalavras(texto=texto,
                                           palavras_especificas=['aqui','vai','texto','exemplo','contagem'])

  for freq in frequencias:
      print(freq)

  ```

  Output:

  ```python  
  ('exemplo', 3)
  ('texto', 2)
  ('aqui', 1)
  ('vai', 1)
  ('contagem', 1)
  ```

  Ainda, pode-se solicitar que seja retornado apenas um valor <i>x</i> de resultados do topo da listagem de frequ√™ncias. No exemplo abaixo, queremos apenas os top 3 mais frequentes da listagem passada (caso a listagem de palavras espec√≠ficas n√£o seja passada, o valor n_top sera da listagem padr√£o de todas as palavras do texto).

  ```python
  from ferramentas_basicas_pln import contarFrequenciaDePalavras

  texto = '''Aqui vai mais um exemplo de texto de exemplo para uma 
  demonstra√ß√£o de contagem de palavras num texto de exemplo com 
  v√°rias palavras.'''

  frequencias = contarFrequenciaDePalavras(texto=texto,
                                           palavras_especificas=['aqui','vai','texto','exemplo','contagem'],
                                           n_top=3)

  for freq in frequencias:
      print(freq)
  ```

  Output:

  ```python
  >>>('exemplo', 3)
  ('texto', 2)
  ('aqui', 1)
  ```


</details>


### ‚öôÔ∏è Fun√ß√µes mais complexas ‚öôÔ∏è

<details>
  <summary>Tokeniza√ß√£o de textos  <i>(clique para expandir)</i></summary>
  <br> 
  
  ```python
  from ferramentas_basicas_pln import tokenizarTexto
  
  texto = '''Este √© mais um texto de exemplo para a tokeniza√ß√£o!!! Vamos usar caracteres, 
  especiais tamb√©m @igorc.s e segue l√°?!'''
  
  tokenizacao = tokenizarTexto(texto)
  
  print(tokenizacao)
  ```

  Output:
  
  ```python
  ['este', '√©', 'mais', 'um', 'texto', 'de', 'exemplo', 'para', 'a', 'tokeniza√ß√£o', 'vamos', 'usar', 'caracteres', 'especiais', 'tamb√©m', 'igorcs', 'e', 'segue', 'l√°']
  ```

  <br>
  <details>
    <summary>Tokeniza√ß√£o removendo palavras de escape/stopwords  <i>(clique para expandir)</i></summary>
    <br>
    Palavras de escape ou stopwords s√£o palavras que n√£o apresentam muito significado em frases, dessa forma algumas aplica√ß√µes, a fim de otimizarem seu processamento e tempo de treinamento, removem tais palavras do corpus de texto. Alguns exemplos de stopwords               comuns       s√£o artigos e preposi√ß√µes.
    <br><br>
          
  ```python
  from ferramentas_basicas_pln import tokenizarTexto

  texto = '''Este √© mais um texto de exemplo para a tokeniza√ß√£o!!! Vamos usar caracteres, 
  especiais tamb√©m @igorc.s e segue l√°?!'''

  tokenizacao = tokenizarTexto(texto,remover_palavras_de_escape=True)

  print(tokenizacao)
  
  ```

  Output:

  ```python
  ['este', '√©', 'mais', 'um', 'texto', 'exemplo', 'para', 'tokeniza√ß√£o', 'vamos', 'usar', 'caracteres', 'especiais', 'tamb√©m', 'igorcs', 'segue', 'l√°']
  ```

  </details>
  
  <details>
    <summary>Tokeniza√ß√£o removendo palavras de escape/stopwords com lista de stopwords personalizada  <i>(clique para expandir)</i></summary>
    <br>
    Podemos tamb√©m selecionar uma lista de stopwords personalizada, adicionando ou removendo da lista padr√£o <i>lista_com_palavras_de_escape_padrao_tokenizacao</i> ou at√© mesmo criando uma lista totalmente √∫nica.
    <br><br>
  
  ```python
  from ferramentas_basicas_pln import tokenizarTexto
  from ferramentas_basicas_pln import lista_com_palavras_de_escape_padrao_tokenizacao

  texto = '''Este √© mais um texto de exemplo para a tokeniza√ß√£o!!! Vamos usar caracteres, 
  especiais tamb√©m @igorc.s e segue l√°?!'''

  lista_stop_words_personalizada = lista_com_palavras_de_escape_padrao_tokenizacao + ['este','mais','um','para','tamb√©m','l√°']

  tokenizacao = tokenizarTexto(texto,remover_palavras_de_escape=True,lista_com_palavras_de_escape=lista_stop_words_personalizada)

  print(tokenizacao)
  ```

  Output:

  ```python
  ['este', '√©', 'texto', 'exemplo', 'tokeniza√ß√£o', 'vamos', 'usar', 'caracteres', 'especiais', 'igorcs', 'segue']
  ```
  
  </details>
  
  <details>
    <summary>Tokeniza√ß√£o mais completa  <i>(clique para expandir)</i></summary>
    <br>
    Pode-se tamb√©m utilizar uma formata√ß√£o pr√©via antes do processo de tokeniza√ß√£o. No exemplo abaixo passa-se o texto para a forma can√¥nica antes de tokeniz√°-lo. Ou seja, palavras como "cora√ß√£o" passam a ser "coracao", perdendo seus acentos, "√ß", etc.
    <br><br>
      
  ```python
  from ferramentas_basicas_pln import tokenizarTexto
  from ferramentas_basicas_pln import lista_com_palavras_de_escape_padrao_tokenizacao

  texto = '''Este √© mais um texto de exemplo para a tokeniza√ß√£o!!! Vamos usar caracteres, 
  especiais tamb√©m @igorc.s e segue l√°?!'''

  lista_stop_words_personalizada = lista_com_palavras_de_escape_padrao_tokenizacao + ['este','mais','um','para','tamb√©m','l√°']

  texto = formatacaoTotalDeTexto(texto,padronizar_forma_canonica=True)

  tokenizacao = tokenizarTexto(texto=texto,
                               remover_palavras_de_escape=True,
                               lista_com_palavras_de_escape=lista_stop_words_personalizada,
                               desconsiderar_acentuacao_nas_palavras_de_escape=True)

  print(tokenizacao)
  ```

  Output:

  ```python
  ['texto', 'exemplo', 'tokenizacao', 'vamos', 'usar', 'caracteres', 'especiais', 'igorcs', 'segue']
  ```
  
  </details>
  
</details>




## üë§ Autores

- [@IgorCaetano](https://github.com/IgorCaetano)


## ü§ù Usado por


- Esse projeto √© usado na etapa de pr√©-processamento de textos no projeto **[WOKE](https://github.com/iaehistoriaUFSC/Repositorio_UFSC)** do Grupo de Estudos e Pesquisa em IA e Hist√≥ria da UFSC.
- *Se voc√™, sua empresa, organiza√ß√£o, etc usarem este programa, por favor, notifique os autores para adi√ß√£o neste campo.*

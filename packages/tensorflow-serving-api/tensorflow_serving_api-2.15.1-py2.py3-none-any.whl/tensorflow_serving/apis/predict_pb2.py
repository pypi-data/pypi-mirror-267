# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow_serving/apis/predict.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
from tensorflow_serving.apis import model_pb2 as tensorflow__serving_dot_apis_dot_model__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n%tensorflow_serving/apis/predict.proto\x12\x12tensorflow.serving\x1a&tensorflow/core/framework/tensor.proto\x1a#tensorflow_serving/apis/model.proto\"\xdc\x02\n\x0ePredictRequest\x12\x31\n\nmodel_spec\x18\x01 \x01(\x0b\x32\x1d.tensorflow.serving.ModelSpec\x12>\n\x06inputs\x18\x02 \x03(\x0b\x32..tensorflow.serving.PredictRequest.InputsEntry\x12\x15\n\routput_filter\x18\x03 \x03(\t\x12L\n\x18predict_streamed_options\x18\x05 \x01(\x0b\x32*.tensorflow.serving.PredictStreamedOptions\x12\x16\n\tclient_id\x18\x06 \x01(\x0cH\x00\x88\x01\x01\x1a\x46\n\x0bInputsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tensorflow.TensorProto:\x02\x38\x01\x42\x0c\n\n_client_idJ\x04\x08\x04\x10\x05\"\xaf\x02\n\x16PredictStreamedOptions\x12N\n\rrequest_state\x18\x01 \x01(\x0e\x32\x37.tensorflow.serving.PredictStreamedOptions.RequestState\x12Y\n\x10split_dimensions\x18\x02 \x03(\x0b\x32?.tensorflow.serving.PredictStreamedOptions.SplitDimensionsEntry\x1a\x36\n\x14SplitDimensionsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x05:\x02\x38\x01\"2\n\x0cRequestState\x12\x08\n\x04NONE\x10\x00\x12\t\n\x05SPLIT\x10\x01\x12\r\n\tEND_SPLIT\x10\x02\"\xd0\x01\n\x0fPredictResponse\x12\x31\n\nmodel_spec\x18\x02 \x01(\x0b\x32\x1d.tensorflow.serving.ModelSpec\x12\x41\n\x07outputs\x18\x01 \x03(\x0b\x32\x30.tensorflow.serving.PredictResponse.OutputsEntry\x1aG\n\x0cOutputsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tensorflow.TensorProto:\x02\x38\x01\x42\x03\xf8\x01\x01\x62\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'tensorflow_serving.apis.predict_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\370\001\001'
  _PREDICTREQUEST_INPUTSENTRY._options = None
  _PREDICTREQUEST_INPUTSENTRY._serialized_options = b'8\001'
  _PREDICTSTREAMEDOPTIONS_SPLITDIMENSIONSENTRY._options = None
  _PREDICTSTREAMEDOPTIONS_SPLITDIMENSIONSENTRY._serialized_options = b'8\001'
  _PREDICTRESPONSE_OUTPUTSENTRY._options = None
  _PREDICTRESPONSE_OUTPUTSENTRY._serialized_options = b'8\001'
  _PREDICTREQUEST._serialized_start=139
  _PREDICTREQUEST._serialized_end=487
  _PREDICTREQUEST_INPUTSENTRY._serialized_start=397
  _PREDICTREQUEST_INPUTSENTRY._serialized_end=467
  _PREDICTSTREAMEDOPTIONS._serialized_start=490
  _PREDICTSTREAMEDOPTIONS._serialized_end=793
  _PREDICTSTREAMEDOPTIONS_SPLITDIMENSIONSENTRY._serialized_start=687
  _PREDICTSTREAMEDOPTIONS_SPLITDIMENSIONSENTRY._serialized_end=741
  _PREDICTSTREAMEDOPTIONS_REQUESTSTATE._serialized_start=743
  _PREDICTSTREAMEDOPTIONS_REQUESTSTATE._serialized_end=793
  _PREDICTRESPONSE._serialized_start=796
  _PREDICTRESPONSE._serialized_end=1004
  _PREDICTRESPONSE_OUTPUTSENTRY._serialized_start=933
  _PREDICTRESPONSE_OUTPUTSENTRY._serialized_end=1004
# @@protoc_insertion_point(module_scope)

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2im: convert from one image type to another image type\n",
    "\n",
    "\n",
    "the function takes three parameters:\n",
    "\n",
    "1. **Source Image**: This is the first parameter and represents the image you intend to convert.\n",
    "\n",
    "2. **Source Image Type Description**: The second parameter provides a detailed description of the input image's current format and characteristics. This description is broken down into four key attributes:\n",
    "    - **lib**: A string indicating the library associated with the image (e.g., 'numpy', 'PIL', 'torch').\n",
    "    - **color_channel**: An optional attribute that specifies the color channel format of the image, such as 'gray', 'rgb', 'bgr', 'rgba', or 'graya'.\n",
    "    - **image_dtype**: An optional attribute that defines the data type of the image pixels. including 'uint8', 'uint16', 'uint32', 'uint64',\n",
    "            'int8', 'int16', 'int32', 'int64',\n",
    "            'float32(0to1)', 'float32(-1to1)',\n",
    "            'float64(0to1)', 'float64(-1to1)',\n",
    "            'double(0to1)', 'double(-1to1)'.\n",
    "    - **device**: An optional attribute that indicates the computing device ('cpu' or 'gpu') on which the image is stored or processed.\n",
    "\n",
    "3. **Target Image Type Specification**: The same structure as the second parameter to specify the target image type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 1, 20, 20]) torch.uint8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.im2im import im2im\n",
    "\n",
    "source = np.random.randint(0, 256, (20, 20, 3), dtype=np.uint8)\n",
    "target = im2im(source, {\"lib\": \"numpy\"}, {\"lib\": \"torch\", \"color_channel\":\"gray\", \"image_dtype\": \"uint8\"})\n",
    "\n",
    "print(type(target), target.shape, target.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2im_code: convertion code from one image type to another image type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from torchvision.transforms import functional as v1F\n",
      "import torch\n",
      "image = torch.from_numpy(source)\n",
      "image = image.permute(2, 0, 1)\n",
      "image = image.unsqueeze(0)\n",
      "target = v1F.rgb_to_grayscale(image)\n"
     ]
    }
   ],
   "source": [
    "from src.im2im import im2im_code\n",
    "\n",
    "code = im2im_code(\"source\", {\"lib\": \"numpy\"}, \"target\", {\"lib\": \"torch\", \"color_channel\":\"gray\", \"image_dtype\": \"uint8\"})\n",
    "\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2im_path: intermediate image description during the convertion from one image type to another image type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_representation': 'numpy.ndarray', 'color_channel': 'rgb', 'channel_order': 'channel last', 'minibatch_input': False, 'image_data_type': 'uint8', 'device': 'cpu'}\n",
      "{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel last', 'minibatch_input': False, 'image_data_type': 'uint8', 'device': 'cpu'}\n",
      "{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel first', 'minibatch_input': False, 'image_data_type': 'uint8', 'device': 'cpu'}\n",
      "{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel first', 'minibatch_input': True, 'image_data_type': 'uint8', 'device': 'cpu'}\n",
      "{'data_representation': 'torch.tensor', 'color_channel': 'gray', 'channel_order': 'channel first', 'minibatch_input': True, 'image_data_type': 'uint8', 'device': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "from src.im2im import im2im_path\n",
    "\n",
    "all_img_desc = im2im_path({\"lib\": \"numpy\"}, {\"lib\": \"torch\", \"color_channel\":\"gray\", \"image_dtype\": \"uint8\"})\n",
    "\n",
    "for img_desc in all_img_desc:\n",
    "    print(img_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Extension\n",
    "\n",
    "Our package is designed for easy knowledge graph extension.\n",
    "\n",
    "After understanding the knowledge graph construction mechanism, you can utilize functions\n",
    "`add_meta_values_for_image`, \n",
    "`add_edge_factory_cluster`,\n",
    "`add_conversion_for_metadata_pairs`, \n",
    "each tailored for different extension needs. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

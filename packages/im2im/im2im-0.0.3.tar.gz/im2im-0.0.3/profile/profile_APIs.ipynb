{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a39ba89-0351-43ac-ad19-d69fed66aa2b",
   "metadata": {},
   "source": [
    "# Profiling APIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cb638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Assume the current working directory is where the this notebook file is located \n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(os.path.join(project_dir, \"src\"))\n",
    "# Alternatively you can install package directly from the Pypi. \n",
    "# %pip install im2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7d646b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py-cpuinfo in /home/fei/miniconda3/envs/tf-wsl/lib/python3.12/site-packages (9.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gputil in /home/fei/miniconda3/envs/tf-wsl/lib/python3.12/site-packages (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU: Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz\n",
      "GPU:0: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "%pip install py-cpuinfo\n",
    "%pip install gputil\n",
    "import cpuinfo\n",
    "import GPUtil\n",
    "cpu_name = cpuinfo.get_cpu_info()['brand_raw']\n",
    "print(f\"CPU: {cpu_name}\")\n",
    "\n",
    "gpus = GPUtil.getGPUs()\n",
    "print(f\"GPU:0: {GPUtil.getGPUs()[0].name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0bcd9e-bea3-496f-9048-db58762babd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1684 function calls in 0.001 seconds\n",
      "\n",
      "Converson code from \"source\" to \"target\" is \n",
      "import torch\n",
      "from torchvision.transforms import functional as v1F\n",
      "image = torch.from_numpy(source)\n",
      "image = image.permute(2, 0, 1)\n",
      "image = image.unsqueeze(0)\n",
      "target = v1F.rgb_to_grayscale(image)\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "from im2im import im2im_code, _code_generator\n",
    "\n",
    "def clear_cache_in_code_generator():\n",
    "    _code_generator._cache = {}\n",
    "    \n",
    "clear_cache_in_code_generator()\n",
    "with cProfile.Profile() as profile:\n",
    "    code = im2im_code(\"source\", {\"lib\": \"numpy\"}, \"target\", {\"lib\": \"torch\", \"color_channel\":\"gray\", \"image_dtype\": \"uint8\"})\n",
    "\n",
    "    results = pstats.Stats(profile)\n",
    "    results.print_stats(0)\n",
    "\n",
    "    print(f'Conversion code from \"source\" to \"target\" is \\n{code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de7f8b36-ad5b-451c-8a65-ff04fdc6efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1712 function calls in 0.023 seconds\n",
      "\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 2000, 2000]) torch.uint8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from im2im import im2im\n",
    "\n",
    "clear_cache_in_code_generator()\n",
    "source = np.random.randint(0, 256, (2000, 2000, 3), dtype=np.uint8)\n",
    "with cProfile.Profile() as profile:\n",
    "    target = im2im(source, {\"lib\": \"numpy\"}, {\"lib\": \"torch\", \"color_channel\":\"gray\", \"image_dtype\": \"uint8\"})\n",
    "\n",
    "    results = pstats.Stats(profile)\n",
    "    results.print_stats(0)\n",
    "\n",
    "    print(type(target), target.shape, target.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa498faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1510 function calls in 0.001 seconds\n",
      "\n",
      "{'data_representation': 'numpy.ndarray', 'color_channel': 'rgb', 'channel_order': 'channel last', 'minibatch_input': False, 'image_data_type': 'uint8', 'device': 'cpu'}\n",
      "{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel last', 'minibatch_input': False, 'image_data_type': 'uint8', 'device': 'cpu'}\n",
      "{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel first', 'minibatch_input': False, 'image_data_type': 'uint8', 'device': 'cpu'}\n",
      "{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel first', 'minibatch_input': True, 'image_data_type': 'uint8', 'device': 'cpu'}\n",
      "{'data_representation': 'torch.tensor', 'color_channel': 'gray', 'channel_order': 'channel first', 'minibatch_input': True, 'image_data_type': 'uint8', 'device': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "from im2im import im2im_path\n",
    "\n",
    "clear_cache_in_code_generator()\n",
    "with cProfile.Profile() as profile:\n",
    "    steps = im2im_path({\"lib\": \"numpy\"}, {\"lib\": \"torch\", \"color_channel\":\"gray\", \"image_dtype\": \"uint8\"})\n",
    "    \n",
    "    results = pstats.Stats(profile)\n",
    "    results.print_stats(0)\n",
    "\n",
    "    for step in steps:\n",
    "        print(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

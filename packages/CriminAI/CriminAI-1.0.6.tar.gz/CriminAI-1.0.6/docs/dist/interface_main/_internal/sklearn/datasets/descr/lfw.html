<!DOCTYPE html>

<html lang="fr" data-content_root="../../../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>The Labeled Faces in the Wild face recognition dataset &#8212; Documentation CriminAI 0.1.4</title>
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/alabaster.css?v=12dfc556" />
    <script src="../../../../../../_static/documentation_options.js?v=750eb482"></script>
    <script src="../../../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../../_static/translations.js?v=d99ca74e"></script>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Recherche" href="../../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="the-labeled-faces-in-the-wild-face-recognition-dataset">
<span id="labeled-faces-in-the-wild-dataset"></span><h1>The Labeled Faces in the Wild face recognition dataset<a class="headerlink" href="#the-labeled-faces-in-the-wild-face-recognition-dataset" title="Link to this heading">Â¶</a></h1>
<p>This dataset is a collection of JPEG pictures of famous people collected
over the internet, all details are available on the official website:</p>
<p><a class="reference external" href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a></p>
<p>Each picture is centered on a single face. The typical task is called
Face Verification: given a pair of two pictures, a binary classifier
must predict whether the two images are from the same person.</p>
<p>An alternative task, Face Recognition or Face Identification is:
given the picture of the face of an unknown person, identify the name
of the person by referring to a gallery of previously seen pictures of
identified persons.</p>
<p>Both Face Verification and Face Recognition are tasks that are typically
performed on the output of a model trained to perform Face Detection. The
most popular model for Face Detection is called Viola-Jones and is
implemented in the OpenCV library. The LFW faces were extracted by this
face detector from various online websites.</p>
<p><strong>Data Set Characteristics:</strong></p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>Classes</p></td>
<td><p>5749</p></td>
</tr>
<tr class="row-even"><td><p>Samples total</p></td>
<td><p>13233</p></td>
</tr>
<tr class="row-odd"><td><p>Dimensionality</p></td>
<td><p>5828</p></td>
</tr>
<tr class="row-even"><td><p>Features</p></td>
<td><p>real, between 0 and 255</p></td>
</tr>
</tbody>
</table>
<p><a href="#id1"><span class="problematic" id="id2">|details-start|</span></a>
<strong>Usage</strong>
<a href="#id3"><span class="problematic" id="id4">|details-split|</span></a></p>
<p><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> provides two loaders that will automatically download,
cache, parse the metadata files, decode the jpeg and convert the
interesting slices into memmapped numpy arrays. This dataset size is more
than 200 MB. The first load typically takes more than a couple of minutes
to fully decode the relevant part of the JPEG files into numpy arrays. If
the dataset has  been loaded once, the following times the loading times
less than 200ms by using a memmapped version memoized on the disk in the
<code class="docutils literal notranslate"><span class="pre">~/scikit_learn_data/lfw_home/</span></code> folder using <code class="docutils literal notranslate"><span class="pre">joblib</span></code>.</p>
<p>The first loader is used for the Face Identification task: a multi-class
classification task (hence supervised learning):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_lfw_people</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span> <span class="o">=</span> <span class="n">fetch_lfw_people</span><span class="p">(</span><span class="n">min_faces_per_person</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">lfw_people</span><span class="o">.</span><span class="n">target_names</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Ariel Sharon</span>
<span class="go">Colin Powell</span>
<span class="go">Donald Rumsfeld</span>
<span class="go">George W Bush</span>
<span class="go">Gerhard Schroeder</span>
<span class="go">Hugo Chavez</span>
<span class="go">Tony Blair</span>
</pre></div>
</div>
<p>The default slice is a rectangular shape around the face, removing
most of the background:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;float32&#39;)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1288, 1850)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1288, 50, 37)</span>
</pre></div>
</div>
<p>Each of the <code class="docutils literal notranslate"><span class="pre">1140</span></code> faces is assigned to a single person id in the <code class="docutils literal notranslate"><span class="pre">target</span></code>
array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_people</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1288,)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">lfw_people</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
<span class="go">[5, 6, 3, 1, 0, 1, 3, 4, 3, 0]</span>
</pre></div>
</div>
<p>The second loader is typically used for the face verification task: each sample
is a pair of two picture belonging or not to the same person:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_lfw_pairs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_pairs_train</span> <span class="o">=</span> <span class="n">fetch_lfw_pairs</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">lfw_pairs_train</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
<span class="go">[&#39;Different persons&#39;, &#39;Same person&#39;]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_pairs_train</span><span class="o">.</span><span class="n">pairs</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2200, 2, 62, 47)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_pairs_train</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2200, 5828)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">lfw_pairs_train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2200,)</span>
</pre></div>
</div>
<p>Both for the <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_lfw_people()</span></code> and
<code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_lfw_pairs()</span></code> function it is
possible to get an additional dimension with the RGB color channels by
passing <code class="docutils literal notranslate"><span class="pre">color=True</span></code>, in that case the shape will be
<code class="docutils literal notranslate"><span class="pre">(2200,</span> <span class="pre">2,</span> <span class="pre">62,</span> <span class="pre">47,</span> <span class="pre">3)</span></code>.</p>
<p>The <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.fetch_lfw_pairs()</span></code> datasets is subdivided into
3 subsets: the development <code class="docutils literal notranslate"><span class="pre">train</span></code> set, the development <code class="docutils literal notranslate"><span class="pre">test</span></code> set and
an evaluation <code class="docutils literal notranslate"><span class="pre">10_folds</span></code> set meant to compute performance metrics using a
10-folds cross validation scheme.</p>
<p><a href="#id5"><span class="problematic" id="id6">|details-end|</span></a></p>
<aside class="topic">
<p class="topic-title">References:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://vis-www.cs.umass.edu/lfw/lfw.pdf">Labeled Faces in the Wild: A Database for Studying Face Recognition
in Unconstrained Environments.</a>
Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.
University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">Examples:</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_applications_plot_face_recognition.py</span></p></li>
</ul>
</aside>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../../index.html">CriminAI</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../modules.html">CriminAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../setup.html">setup module</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Recherche rapide</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, ZOUARI Matis, SUTTER ClÃ©mence, PEREZ Lisa, ZHONG Zhihan.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../../../../../../_sources/dist/interface_main/_internal/sklearn/datasets/descr/lfw.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>